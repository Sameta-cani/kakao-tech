# 데이터 전처리

데이터 전처리는 원시 데이터를 분석 및 모델링에 적합하도록 정제, 변환, 통합 등의 과정을 거쳐 변환하는 작업이다. 데이터의 속성이나 환경이 다양하므로 각각에 맞는 전략이 필요하며 다음과 같은 이점이 있다.

- 데이터 품질 향상
- 모델 성능 최적화
- 분석의 신뢰성 향상
- 데이터 활용의 효율성 향상

## 전처리 과정

- 수치형 데이터
  - 결측값 및 이상치 처리: 평균값, 중앙값, 이웃값 등의 대푯값이나 해당 행을 제거하는 등
  - 스케일링 및 정규화
- 범주형 데이터
  - 결측값 및 이상치 처리: 최빈값으로 대체
  - 레이블 인코딩(One-Hot Encoding, etc.)
- 날짜 및 시간 데이터 전처리
  - 형식 변환 및 추출(년, 월, 일, etc.)
- 텍스트 데이터 전처리
  - 텍스트 정제 및 벡터화(TF-IDF, Embedding, etc.)

## 결측치

결측치의 종류에는 MCAR, MAR, 그리고 MNAR이 있지만, 한 데이터에서 여러 결측치가 나오진 않고, 현업에서도 크게 구분짓지는 않음

결측치의 원인으로는 데이터 입력 오류, 응답자의 미응답, 데이터 수집 과정의 문제 등이 있다.

## 이상치

데이터 분포에서 벗어난 극단적인 값으로 통계적 분석과 모델 성능에 영향을 줄 수 있다.

이상치의 원인으로는 데이터 입력 오류, 데이터 수집 문제, 자연적 변동성 등이 있다.

## 데이터 변환

### 스케일링

동일한 스케일로 조정하여 계산의 안정성과 속도 향상을 기대할 수 있다.

**표준화(Standardization)**

데이터를 $N(0, 1^2)$로 변환

$$
z = \frac{(x - \mu)}{\sigma}
$$

**정규화(Normalization)**

데이터를 특정범위로 변환하는 과정(주로 0~1)

$$
x' = \frac{(x - x_{\text{min}})}{(x_{\text{max}} - x_{\text{min}})}
$$

### 인코딩

범주형 데이터를 숫자 또는 이진 벡터로 변환한다.

<img width="377" alt="스크린샷 2024-07-03 오후 6 18 00" src="https://github.com/Sameta-cani/kakao-tech/assets/83288284/931053bf-8be2-4c92-99a3-61cad8c14d14">

원-핫 인코딩은 많은 범주를 변환할 시, 고차원 데이터로 변환되어 메모리 사용량이 증가하는 문제 발생

### 데이터 통합 및 변형

- 데이터 합치기: `concat()`, `merge()`
- 데이터 집계: `info()`, `describe()`
- 데이터 그룹화: `groupby()`, `pivot_table()`
- 데이터 변형(재구조화): `melt()`, `wide_to_long()`
- 데이터 피벗: `pivot()`

## Advanced

### 파생 변수 생성

파생 변수란, 기존 데이터를 조합하여 만들어진 새로운 변수로, 데이터의 정보량을 증가시켜 분석 및 모델링 성능을 향상시켜준다.

$$
\text{BMI} = \frac{\text{체중(kg)}}{\text{키(m)}^2}
$$

### 데이터 샘플링

전체 데이터셋에서 일부 데이터를 선택하여 분석이나 모델링에 사용하는 과정이다. 랜덤 샘플링, 층화 샘플링 등의 방법이 있는데, 중요한 점은 샘플링된 데이터가 모집단의 특성을 대표해야 한다는 것이다.

### 차원 축소 기법

차원 축소 기법은 고차원 데이터의 차원을 줄여 데이터의 복잡성을 낮추고 시각화 및 분석을 용이하게 만드는 방법으로 주성분 분석(PCA), 선형 판별 분석(LDA), t-SNE와 같은 기법들이 대표적이다. 이러한 기법들은 데이터의 중요한 정보를 최대한 보존하면서 불필요한 변수를 제거해 계산 효율성을 높이고, 모델의 과적합을 방지하는 데 도움을 준다. 차원 축소는 특히 데이터 시각화와 이해를 돕고, 데이터의 본질적인 구조를 파악하는 데 유용하다.

<img width="522" alt="스크린샷 2024-07-03 오후 6 33 26" src="https://github.com/Sameta-cani/kakao-tech/assets/83288284/9d0f321f-680e-41df-b70c-eb51ad29fa96">

## 데이터 전처리 최적화

반복적이고 일관된 전처리 작업을 자동화하여 효율성을 높이기 위해서 **파이프라인**을 구축한다. 즉, 전처리 작업의 알관성과 재현성을 보장한다.

최적화할 다른 사항은 **대용량 데이터 처리**로 다음과 같은 방법으로 해결한다.
- 분산 처리: 데이터를 여러 노드에 분산하여 동시에 처리(Hadoop, Spark)
- 병렬 처리: 데이터를 여러 프로세스에서 동시에 처리(multiprocessing, Dask)
- 메모리 관리: 메모리 사용을 최적화(데이터 타입 최적화, 청크 단위 처리)

추가로, 다음과 같은 최적화 방법이 있다.
- 최적화된 알고리즘
- 코딩 스타일 개선
- 작업에 적합한 데이터 구조를 사용
- pandas, NumPy, Dask 등의 라이브러리를 적절히 사용